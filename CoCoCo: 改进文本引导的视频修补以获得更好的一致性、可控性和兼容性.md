# 《Towards Language-Driven Video Inpainting via Multimodal Large Language Models》

## 研究背景

如题，视频修复存在一致性，可控性，兼容性的问题。下文中的三个方法便对应着解决了这三个问题。

## 解决方法

### 运动捕捉模块

#### Damped Global Attention, DGA（阻尼全局注意力）

目的：时间注意力机制无法关注空间区域，无法捕捉空间区域，为解决运动一致性。  

方法：输入特征大小调整（减小计算量）；特征展平；多头自注意力；特征恢复。

#### Textual Cross-Attention（文本交叉注意力）

目的：解决无法从文本提示中提取运动细节。  
方法：使用视觉输入地展平向量作为查询（query），使用文本嵌入作为key和value。

### 实例感知区域选择策略

目的：AVID使用随机掩码选择进行修复（随机掩码可能无法覆盖文本对应对象，导致训练时包含来自两个不同场景地帧），但是我们应该保持帧间掩码的一致性。    
方法：使用GroundingDINO检测第一帧中的文本提示对应的区域，并通过TokenSpan保持帧间的一致性。  
在实际训练时，将在精确掩码，随机掩码，无提示这三种中随机选一个，以增加鲁棒性。

### 个性化模型的兼容性

目的：将图像生成模型适用于视频修复，但是由于视频修复模型和图像生成模型的输入维度并不相同，并且生成和修复能力的融合也存在问题。

方法：利用**任务向量**的思想将图像生成模型转换为修复模型，下文我们将专门介绍一下任务向量的思想。首先，我们将生成模型表示为θ<sub>base</sub>（上文说生成模型的输入维度较小，为4维，因此我们这里填充零将其扩展为9维）。将修复模型表示为θ<sub>ip</sub>，将个性化T2I模型表示为θ<sub>p</sub>。根据任务向量的思想，我们将修复任务向量和个性化任务向量表示为：  
τ_ip = θ_ip - θ_base  
τ_p = θ_p - θ_base  
然后创建一个新的模型：
θ_new = θ_base + ατ_ip + βτ_p  
**任务向量**：是一种模型迁移和任务组合的技术。它通过计算两个模型参数之间的差异（即任务向量），然后将这些差异应用于基础模型，生成一个新的模型，以上述为例进行说明。

θ<sub>base</sub>就是基础模型，θ<sub>p</sub>和θ<sub>ip</sub>及就是特定任务的模型，$\tau_{ip}$和$\tau_{p}$就是两个目标任务向量，我们通过将任务向量和基础模型结合，可以生成一个新的模型θ_new。

## 待解决的问题

1.复杂场景的修复问题：多个对象之间互相干扰，运动复杂，视频逻辑复杂。

2.长视频一致性：存在积累误差。

3.高分辨率视频修复效率：压缩技术和特征提取技术。

4.个性化：本文我认为只是初步引入了个性化这个操作，还存在很多可以优化的点。
